{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12830809,"sourceType":"datasetVersion","datasetId":8114587}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-22T14:50:32.144268Z","iopub.execute_input":"2025-08-22T14:50:32.144549Z","iopub.status.idle":"2025-08-22T14:50:32.522618Z","shell.execute_reply.started":"2025-08-22T14:50:32.144527Z","shell.execute_reply":"2025-08-22T14:50:32.521351Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/wiki-cc-openweb/wiki_small_50k/wiki_small_50k.csv\n/kaggle/input/wiki-cc-openweb/openweb_50k (2)/openweb_50k.csv\n/kaggle/input/wiki-cc-openweb/cc_news/cc_news.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset, concatenate_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T14:24:23.192270Z","iopub.execute_input":"2025-08-23T14:24:23.192523Z","iopub.status.idle":"2025-08-23T14:24:26.390951Z","shell.execute_reply.started":"2025-08-23T14:24:23.192496Z","shell.execute_reply":"2025-08-23T14:24:26.390182Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"wiki_ds = load_dataset(\"csv\", data_files=\"/kaggle/input/wiki-cc-openweb/wiki_small_50k/wiki_small_50k.csv\")\nowt_ds = load_dataset(\"csv\", data_files=\"/kaggle/input/wiki-cc-openweb/openweb_50k (2)/openweb_50k.csv\")\ncc_news_ds = load_dataset(\"csv\", data_files=\"/kaggle/input/wiki-cc-openweb/cc_news/cc_news.csv\")\ntrain_ds = concatenate_datasets([wiki_ds[\"train\"],owt_ds[\"train\"],cc_news_ds[\"train\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T14:24:26.392694Z","iopub.execute_input":"2025-08-23T14:24:26.393042Z","iopub.status.idle":"2025-08-23T14:24:42.176350Z","shell.execute_reply.started":"2025-08-23T14:24:26.393025Z","shell.execute_reply":"2025-08-23T14:24:42.175817Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38fa202bcea340a6898a62c8e484c63c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef903a76f8a54217939c46371e113823"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b5a1d733a9744e79a19cbf127f0cd67"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from tokenizers import ByteLevelBPETokenizer\nspecial_tokens = ['<s>','<pad>','</s>','<unk>','<mask>']\ntokenizer = ByteLevelBPETokenizer()\ntokenizer.train_from_iterator([x['text'] for x in train_ds], vocab_size = 10_000,min_frequency =2, special_tokens=special_tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T14:25:10.661933Z","iopub.execute_input":"2025-08-23T14:25:10.662670Z","iopub.status.idle":"2025-08-23T14:27:09.611497Z","shell.execute_reply.started":"2025-08-23T14:25:10.662638Z","shell.execute_reply":"2025-08-23T14:27:09.610689Z"}},"outputs":[{"name":"stdout","text":"\n\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"tokenizer.save_model(\"/kaggle/working/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T14:27:24.481569Z","iopub.execute_input":"2025-08-23T14:27:24.482192Z","iopub.status.idle":"2025-08-23T14:27:24.493222Z","shell.execute_reply.started":"2025-08-23T14:27:24.482139Z","shell.execute_reply":"2025-08-23T14:27:24.492406Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/vocab.json', '/kaggle/working/merges.txt']"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from transformers import RobertaTokenizer\ntokenizer = RobertaTokenizer.from_pretrained(\"/kaggle/working/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:32:33.412260Z","iopub.execute_input":"2025-08-22T15:32:33.412524Z","iopub.status.idle":"2025-08-22T15:32:33.438948Z","shell.execute_reply.started":"2025-08-22T15:32:33.412506Z","shell.execute_reply":"2025-08-22T15:32:33.437930Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def tokenize(batch):\n    return tokenizer(batch[\"text\"], truncation=True, max_length=254)\n\ntrain_dataset = train_ds.map(tokenize, batched=True, remove_columns=[\"text\"])\ntrain_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:34:33.957188Z","iopub.execute_input":"2025-08-22T15:34:33.958391Z","iopub.status.idle":"2025-08-22T15:50:31.212394Z","shell.execute_reply.started":"2025-08-22T15:34:33.958352Z","shell.execute_reply":"2025-08-22T15:50:31.211387Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/170824 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15ff8768d19a4bbab8ff7d104e592db2"}},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"sample_dataset = train_dataset[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:51:59.329225Z","iopub.execute_input":"2025-08-22T15:51:59.329905Z","iopub.status.idle":"2025-08-22T15:51:59.341208Z","shell.execute_reply.started":"2025-08-22T15:51:59.329860Z","shell.execute_reply":"2025-08-22T15:51:59.340012Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# Real text\n\n\nsample_dataset = []\nfor text in train_ds['text']:\n    enc = tokenizer(text, truncation=True, max_length=254, return_tensors=\"pt\")\n    sample_dataset.append({\n        \"input_ids\": enc[\"input_ids\"].squeeze(0),\n        \"attention_mask\": enc[\"attention_mask\"].squeeze(0)\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:52:57.340229Z","iopub.execute_input":"2025-08-22T15:52:57.340494Z","iopub.status.idle":"2025-08-22T16:08:51.362267Z","shell.execute_reply.started":"2025-08-22T15:52:57.340472Z","shell.execute_reply":"2025-08-22T16:08:51.361196Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"test_dataset = sample_dataset[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:10:36.058947Z","iopub.execute_input":"2025-08-22T16:10:36.059318Z","iopub.status.idle":"2025-08-22T16:10:36.063608Z","shell.execute_reply.started":"2025-08-22T16:10:36.059297Z","shell.execute_reply":"2025-08-22T16:10:36.062741Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"from transformers import (\n    RobertaConfig,\n    RobertaForMaskedLM,\n    DataCollatorForLanguageModeling,\n    Trainer,\n    TrainingArguments,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:23:45.966664Z","iopub.execute_input":"2025-08-22T15:23:45.967125Z","iopub.status.idle":"2025-08-22T15:24:11.654092Z","shell.execute_reply.started":"2025-08-22T15:23:45.967063Z","shell.execute_reply":"2025-08-22T15:24:11.653163Z"}},"outputs":[{"name":"stderr","text":"2025-08-22 15:23:53.571424: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755876233.834870      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755876233.909321      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"config = RobertaConfig(\nvocab_size = tokenizer.vocab_size,\nhidden_size = 256, #Embedding size\nnum_hidden_layers = 6,#Number of encoder layers\nnum_attention_heads=4, # Attentions per encoder layer, divisible by 256\nintermediate_size = 1024, #FFN layer size\nmax_position_embeddings=256, #Position Embedding max size = embedding size\ntype_vocab_size =1,\nlayer_norm_eps = 1e-5,\ninitializer_range = 0.02,\npad_token_id = 1,\nbos_token_id = 0,\neos_token_id = 2\n)\nmodel = RobertaForMaskedLM(config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:24:11.655122Z","iopub.execute_input":"2025-08-22T15:24:11.655683Z","iopub.status.idle":"2025-08-22T15:24:11.840374Z","shell.execute_reply.started":"2025-08-22T15:24:11.655661Z","shell.execute_reply":"2025-08-22T15:24:11.839466Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:24:40.298910Z","iopub.execute_input":"2025-08-22T15:24:40.299240Z","iopub.status.idle":"2025-08-22T15:24:40.303846Z","shell.execute_reply.started":"2025-08-22T15:24:40.299220Z","shell.execute_reply":"2025-08-22T15:24:40.302837Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# 4️⃣ Training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./checkpoints\",\n    overwrite_output_dir = False,\n    do_train=True,\n    save_steps=100,\n    logging_steps=100,\n    num_train_epochs=1,\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=2,\n    warmup_steps = 100,\n    logging_dir = \"./logs\",\n    fp16=False,\n    save_total_limit=3,\n    save_strategy = \"steps\",\n    report_to=[]\n)\n\n# 5️⃣ Create Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=sample_dataset,\n    data_collator=data_collator\n)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:15:18.517272Z","iopub.execute_input":"2025-08-22T16:15:18.517560Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2798' max='5339' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2798/5339 3:42:06 < 3:21:50, 0.21 it/s, Epoch 0.52/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>8.540700</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>7.962200</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>7.561200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>7.427800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>7.375600</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>7.336800</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>7.301300</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>7.279600</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>7.270000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>7.232700</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>7.238700</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>7.215000</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>7.182700</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>7.197800</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>7.161100</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>7.175400</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>7.142200</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>7.123300</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>7.117400</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>7.122600</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>7.097700</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>7.086200</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>7.072500</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>7.061500</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>7.055400</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>7.044100</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>7.042700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"import os\nos.listdir(\"/kaggle/working/virtual_documents\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T14:22:49.842902Z","iopub.execute_input":"2025-08-23T14:22:49.843170Z","iopub.status.idle":"2025-08-23T14:22:49.852166Z","shell.execute_reply.started":"2025-08-23T14:22:49.843151Z","shell.execute_reply":"2025-08-23T14:22:49.851036Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/55598890.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/virtual_documents\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/virtual_documents'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/virtual_documents'","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"import json\nimport matplotlib.pyplot as plt\n\n# Path to your trainer_state.json (inside output_dir)\nstate_file = \"./checkpoints/trainer_state.json\"\n\nwith open(state_file, \"r\") as f:\n    trainer_state = json.load(f)\n\n# Extract loss and step history\nsteps = []\nlosses = []\n\nfor log in trainer_state.get(\"log_history\", []):\n    if \"loss\" in log:\n        steps.append(log[\"step\"])\n        losses.append(log[\"loss\"])\n\n# Plot\nplt.figure(figsize=(8, 5))\nplt.plot(steps, losses, marker=\"o\")\nplt.xlabel(\"Step\")\nplt.ylabel(\"Training Loss\")\nplt.title(\"Training Loss over Steps\")\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport matplotlib.pyplot as plt\n\n# Path to your trainer_state.json\nstate_file = \"./checkpoints/trainer_state.json\"\n\nwith open(state_file, \"r\") as f:\n    trainer_state = json.load(f)\n\n# Extract steps, loss, and learning rate\nsteps = []\nlosses = []\nlrs = []\n\nfor log in trainer_state.get(\"log_history\", []):\n    if \"loss\" in log and \"learning_rate\" in log:\n        steps.append(log[\"step\"])\n        losses.append(log[\"loss\"])\n        lrs.append(log[\"learning_rate\"])\n\n# Plot with dual axes\nfig, ax1 = plt.subplots(figsize=(9, 5))\n\ncolor = \"tab:blue\"\nax1.set_xlabel(\"Step\")\nax1.set_ylabel(\"Training Loss\", color=color)\nax1.plot(steps, losses, color=color, marker=\"o\", label=\"Loss\")\nax1.tick_params(axis=\"y\", labelcolor=color)\nax1.grid(True)\n\nax2 = ax1.twinx()  # second y-axis\ncolor = \"tab:red\"\nax2.set_ylabel(\"Learning Rate\", color=color)\nax2.plot(steps, lrs, color=color, linestyle=\"--\", label=\"Learning Rate\")\nax2.tick_params(axis=\"y\", labelcolor=color)\n\nfig.suptitle(\"Training Loss and Learning Rate over Steps\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}